from fastapi import APIRouter, HTTPException, Query
from fastapi.responses import FileResponse
from typing import Dict, Any
import logging
from pathlib import Path
import json
import os
import base64
from io import BytesIO
from PIL import Image
import pandas as pd
import re

from ...utils.config import get_facebook_saved_base
from ...models.schemas import SimpleScrapeRequest
from ..campaign_analysis.services import PDFGenerator

router = APIRouter()
logger = logging.getLogger(__name__)

@router.post("/analyze-local-and-pdf", status_code=200)
async def analyze_local_and_pdf(run_id: str = Query(..., description="ID del run de Apify con los datos locales")):
    """
    Endpoint para an√°lisis local completo con generaci√≥n autom√°tica de PDF.
    
    Basado en el funcionamiento de /analyze-local-only (usa Base64).
    
    Este endpoint:
    1. Carga TODOS los anuncios del CSV
    2. Extrae frames de videos locales
    3. Convierte im√°genes y frames a Base64
    4. Env√≠a TODO a OpenAI (sin l√≠mite de tokens)
    5. Genera PDF profesional autom√°ticamente
    
    Args:
        run_id: ID del run con datos locales guardados
        
    Returns:
        JSON con paths al PDF y reporte JSON generados
    """
    try:
        logger.info("="*80)
        logger.info(f"üöÄ AN√ÅLISIS LOCAL COMPLETO CON PDF - RUN: {run_id}")
        logger.info("="*80)
        
        # PASO 1: Configurar OpenAI
        logger.info("\nüì° PASO 1: Configurando OpenAI...")
        from openai import AsyncOpenAI
        
        api_key = os.getenv("OPENAI_API_KEY") or os.getenv("OPEN_API_KEY")
        if not api_key:
            raise HTTPException(503, "OPENAI_API_KEY no configurada")
        
        openai_client = AsyncOpenAI(api_key=api_key)
        logger.info("   ‚úÖ OpenAI configurado")
        
        # PASO 2: Localizar CSV
        logger.info("\nüìä PASO 2: Localizando dataset...")
        base_dir = get_facebook_saved_base()
        run_dir = base_dir / run_id
        csv_path = run_dir / f"{run_id}.csv"
        
        if not csv_path.exists():
            raise HTTPException(404, f"CSV no encontrado en {csv_path}")
        
        logger.info(f"   ‚úÖ CSV: {csv_path}")
        
        # PASO 3: Cargar TODOS los anuncios
        logger.info("\nüìä PASO 3: Cargando TODOS los anuncios...")
        df = pd.read_csv(csv_path)
        logger.info(f"   üìÑ CSV cargado: {len(df)} anuncios totales")
        
        # PASO 4: Buscar archivos multimedia locales
        logger.info("\nüì¶ PASO 4: Buscando archivos multimedia...")
        media_dir = run_dir / "media"
        video_frames_dir = run_dir / "video_frames"
        
        if not media_dir.exists():
            raise HTTPException(404, f"Directorio media no existe: {media_dir}")
        
        logger.info(f"   üìÅ Media: {media_dir}")
        
        # PASO 4.1: Extraer frames de videos
        logger.info("\nüé¨ Extrayendo frames de videos...")
        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm']
        video_files = [
            f for f in media_dir.iterdir()
            if f.is_file() and f.suffix.lower() in video_extensions
        ]
        
        if video_files:
            logger.info(f"   üìπ {len(video_files)} videos encontrados")
            video_frames_dir.mkdir(exist_ok=True)
            
            try:
                import cv2
                for video_path in video_files:
                    try:
                        logger.info(f"   üîÑ Procesando: {video_path.name}")
                        cap = cv2.VideoCapture(str(video_path))
                        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                        
                        frames_to_extract = [0, frame_count // 2, frame_count - 1]
                        base_name = video_path.stem
                        extracted = 0
                        
                        for i, frame_num in enumerate(frames_to_extract):
                            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
                            ret, frame = cap.read()
                            if ret:
                                frame_filename = f"{base_name}_frame{i}.jpg"
                                frame_path = video_frames_dir / frame_filename
                                cv2.imwrite(str(frame_path), frame)
                                extracted += 1
                        
                        cap.release()
                        logger.info(f"      ‚úÖ {extracted} frames extra√≠dos")
                    except Exception as e:
                        logger.error(f"      ‚ùå Error con {video_path.name}: {e}")
            except ImportError:
                logger.warning("   ‚ö†Ô∏è  OpenCV no disponible")
        
        has_video_frames = video_frames_dir.exists()
        
        # PASO 5: Cargar prompt desde .env o archivo
        logger.info("\nüìÑ PASO 5: Cargando prompt...")
        
        # Primero intentar desde variable de entorno
        prompt_template = os.getenv('PROMPT')
        
        if prompt_template:
            logger.info(f"   ‚úÖ Prompt cargado desde variable PROMPT del .env ({len(prompt_template)} caracteres)")
        else:
            # Si no est√° en .env, buscar archivo
            prompt_file_name = os.getenv('PROMPT_FILE', 'prompt.txt')
            api_service_dir = Path(__file__).parent.parent.parent.parent.parent.parent.parent
            prompt_path = api_service_dir / prompt_file_name
            
            logger.info(f"   üîç Buscando prompt en: {prompt_path}")
            
            if prompt_path.exists():
                with open(prompt_path, "r", encoding="utf-8") as f:
                    prompt_template = f.read().strip()
                logger.info(f"   ‚úÖ Prompt cargado desde {prompt_file_name} ({len(prompt_template)} caracteres)")
            else:
                # Fallback a DEFAULT_PROMPT
                try:
                    from app.api.routes.apify.facebook.analysis.prompts import DEFAULT_PROMPT
                    prompt_template = DEFAULT_PROMPT
                    logger.warning(f"   ‚ö†Ô∏è  Archivo {prompt_file_name} no encontrado, usando DEFAULT_PROMPT")
                except ImportError:
                    prompt_template = "Analiza estos anuncios de Facebook de manera PROFUNDA y DETALLADA. TODO en ESPA√ëOL."
                    logger.warning("   ‚ö†Ô∏è  Usando prompt por defecto b√°sico")
        
        # PASO 6: Preparar contenido para OpenAI con Base64
        logger.info("\nüñºÔ∏è  PASO 6: Preparando im√°genes en Base64...")
        
        # L√≠mite fijo de im√°genes
        MAX_IMAGES = 50
        max_static_images = int(MAX_IMAGES * 0.6)  # 60% = 30 im√°genes
        max_video_frames = int(MAX_IMAGES * 0.4)   # 40% = 20 frames
        
        logger.info(f"   ‚öôÔ∏è  L√≠mite total: {MAX_IMAGES}")
        logger.info(f"   üìä Proporci√≥n: {max_static_images} im√°genes + {max_video_frames} frames de video")
        
        dataset_info = f"""
INFORMACI√ìN DEL DATASET:
- Run ID: {run_id}
- Total de anuncios: {len(df)}
- Im√°genes est√°ticas: {max_static_images}
- Frames de video: {max_video_frames}
- Total multimedia: {MAX_IMAGES}

INSTRUCCI√ìN CR√çTICA: 
- Debes retornar √öNICAMENTE un objeto JSON v√°lido y completo
- TODO en ESPA√ëOL
- An√°lisis PROFUNDO y DETALLADO
- Contrasta im√°genes est√°ticas con frames de video
- No agregues texto adicional antes o despu√©s del JSON

### FORMATO DE SALIDA REQUERIDO (JSON):
{{
  "report_meta": {{
    "generated_role": "Senior Data Scientist & Marketing Director",
    "brand_detected": "(Nombre de la marca identificada en los anuncios)",
    "ranking_metric_used": "(M√©trica principal analizada)",
    "sample_size": "{len(df)} anuncios analizados"
  }},
  "executive_summary": {{
    "performance_overview": "(Resumen estrat√©gico PROFUNDO y DETALLADO de los hallazgos principales. M√≠nimo 200 palabras explicando patrones, tendencias y conclusiones clave)",
    "common_success_patterns": "(Patrones visuales, narrativos o estrat√©gicos recurrentes encontrados)"
  }},
  "top_10_analysis": [
    {{
      "rank": 1,
      "ad_id": "(ID o identificador del anuncio)",
      "metrics": {{
        "primary_metric_value": "(Valor principal si est√° disponible)",
        "ctr": "(CTR si est√° disponible)",
        "spend": "(Gasto si est√° disponible)"
      }},
      "forensic_breakdown": {{
        "hook_strategy": "(An√°lisis DETALLADO del gancho visual en los primeros 3 segundos)",
        "audio_mood": "(Descripci√≥n profesional del audio y su impacto)",
        "narrative_structure": "(Estructura narrativa: Problema/Soluci√≥n, UGC, Testimonial, etc.)"
      }},
      "expert_scores": {{
        "visual_hook": 9,
        "storytelling": 8,
        "brand_integration": 9,
        "conversion_driver": 10
      }},
      "key_takeaway": "(Conclusi√≥n DETALLADA de una o dos frases sobre este anuncio)"
    }}
  ],
  "strategic_recommendations": [
    "(Recomendaci√≥n estrat√©gica 1 - DETALLADA y ACCIONABLE)",
    "(Recomendaci√≥n estrat√©gica 2 - DETALLADA y ACCIONABLE)",
    "(Recomendaci√≥n estrat√©gica 3 - DETALLADA y ACCIONABLE)"
  ]
}}

IMPORTANTE: 
- El campo "performance_overview" debe ser EXTENSIVO y DETALLADO (m√≠nimo 200 palabras)
- Analiza TODOS los anuncios proporcionados, no solo los top 10
- Proporciona insights profundos basados en las im√°genes y frames de video analizados
- Las recomendaciones deben ser espec√≠ficas y accionables
"""
        
        content_blocks = []
        content_blocks.append({
            "type": "text",
            "text": dataset_info + "\n\n" + prompt_template
        })
        
        total_imgs = 0
        total_video_frames = 0
        
        # PRIMERO: Procesar frames de video (40%)
        if has_video_frames:
            logger.info(f"\n   üìπ PASO 6.1: Procesando hasta {max_video_frames} frames de video...")
            video_frame_files = [f for f in video_frames_dir.iterdir() 
                                if f.is_file() and f.suffix.lower() in ['.jpg', '.jpeg', '.png']]
            
            for frame_file in video_frame_files:
                if total_video_frames >= max_video_frames:
                    logger.info(f"   ‚ö†Ô∏è  L√≠mite de {max_video_frames} frames alcanzado")
                    break
                    
                try:
                    with Image.open(frame_file) as img:
                        if img.mode in ('RGBA', 'P'):
                            img = img.convert('RGB')
                        if max(img.size) > 800:
                            img.thumbnail((800, 800), Image.Resampling.LANCZOS)
                        
                        buffered = BytesIO()
                        img.save(buffered, format="JPEG", quality=85, optimize=True)
                        b64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
                        
                        content_blocks.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{b64}",
                                "detail": "high"
                            }
                        })
                        total_video_frames += 1
                        if total_video_frames % 5 == 0:
                            logger.info(f"   ‚úì Procesados {total_video_frames} frames...")
                except Exception as e:
                    logger.error(f"   ‚úó Error en {frame_file.name}: {e}")
            
            logger.info(f"   ‚úÖ Total frames de video: {total_video_frames}")
        
        # SEGUNDO: Procesar im√°genes est√°ticas (60%)
        logger.info(f"\n   üñºÔ∏è  PASO 6.2: Procesando hasta {max_static_images} im√°genes est√°ticas...")
        image_files = [f for f in media_dir.iterdir() 
                      if f.is_file() and f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.webp']]
        
        for img_file in image_files:
            if total_imgs >= max_static_images:
                logger.info(f"   ‚ö†Ô∏è  L√≠mite de {max_static_images} im√°genes alcanzado")
                break
                
            try:
                with Image.open(img_file) as img:
                    if img.mode in ('RGBA', 'P'):
                        img = img.convert('RGB')
                    if max(img.size) > 800:
                        img.thumbnail((800, 800), Image.Resampling.LANCZOS)
                    
                    buffered = BytesIO()
                    img.save(buffered, format="JPEG", quality=85, optimize=True)
                    b64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
                    
                    content_blocks.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{b64}",
                            "detail": "high"
                        }
                    })
                    total_imgs += 1
                    if total_imgs % 10 == 0:
                        logger.info(f"   ‚úì Procesadas {total_imgs} im√°genes...")
            except Exception as e:
                logger.error(f"   ‚úó Error en {img_file.name}: {e}")
        
        logger.info(f"   ‚úÖ Total im√°genes est√°ticas: {total_imgs}")
        
        # PASO 7: Enviar a OpenAI (SIN L√çMITE DE TOKENS)
        logger.info("\nü§ñ PASO 7: Enviando a OpenAI...")
        logger.info(f"   üìä Total: {total_imgs} im√°genes + {total_video_frames} frames de video")
        
        total_assets = total_imgs + total_video_frames
        if total_assets == 0:
            raise HTTPException(400, "No se proces√≥ ninguna multimedia")
        
        response = await openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": "Eres un experto analista de marketing digital y publicidad. IMPORTANTE: Toda tu respuesta debe ser en ESPA√ëOL. Debes analizar anuncios publicitarios de manera profesional y proporcionar an√°lisis profundos y detallados. Retorna √öNICAMENTE un objeto JSON v√°lido."
                },
                {"role": "user", "content": content_blocks}
            ],
            response_format={"type": "json_object"}
            # Sin l√≠mite de max_tokens para permitir respuesta completa
        )
        
        analysis = response.choices[0].message.content
        tokens_used = response.usage.total_tokens
        
        logger.info(f"   ‚úÖ Completado - {tokens_used} tokens usados")
        logger.info(f"   üìù Longitud de respuesta: {len(analysis) if analysis else 0} caracteres")
        logger.info(f"   üìù Tipo de respuesta: {type(analysis)}")
        logger.info(f"   üìù Primeros 200 caracteres: {analysis[:200] if analysis else 'VAC√çO'}")
        
        # PASO 8: Guardar JSON
        logger.info("\nüíæ PASO 8: Guardando an√°lisis...")
        reports_dir = run_dir / "reports"
        reports_dir.mkdir(exist_ok=True)
        
        # Verificar que la respuesta no est√© vac√≠a o rechazada
        if not analysis or analysis.strip() == "":
            logger.error("   ‚ùå OpenAI devolvi√≥ una respuesta VAC√çA")
            raise HTTPException(
                status_code=500,
                detail="OpenAI returned empty response. This may be due to content filtering or API issues."
            )
        
        # Verificar si OpenAI rechaz√≥ la solicitud
        if "no puedo ayudar" in analysis.lower() or "sorry" in analysis.lower() or "cannot" in analysis.lower():
            logger.error(f"   ‚ùå OpenAI rechaz√≥ la solicitud: {analysis[:200]}")
            raw_path = reports_dir / f"{run_id}_raw_response.txt"
            with open(raw_path, 'w', encoding='utf-8') as f:
                f.write(analysis)
            raise HTTPException(
                status_code=500,
                detail=f"OpenAI rechaz√≥ la solicitud. Esto puede deberse a filtros de contenido. Respuesta guardada en {raw_path}"
            )
        
        # Intentar parsear JSON
        analysis_data = None
        try:
            analysis_data = json.loads(analysis)
            logger.info("   ‚úÖ JSON parseado correctamente")
        except json.JSONDecodeError as e:
            logger.warning(f"   ‚ö†Ô∏è  Error parseando JSON: {e}")
            logger.info("   üîß Intentando reparar JSON...")
            
            # Guardar respuesta raw ANTES de intentar reparar
            raw_path = reports_dir / f"{run_id}_raw_response.txt"
            with open(raw_path, 'w', encoding='utf-8') as f:
                f.write(analysis)
            logger.info(f"   üíæ Respuesta raw guardada en: {raw_path}")
            
            try:
                from json_repair import loads as repair_loads
                # loads() repara Y parsea en un solo paso, devuelve dict
                repaired = repair_loads(analysis)
                # Asegurar que sea un dict, no un string
                if isinstance(repaired, str):
                    analysis_data = json.loads(repaired)
                elif isinstance(repaired, dict):
                    analysis_data = repaired
                else:
                    raise ValueError(f"json_repair devolvi√≥ un tipo inesperado: {type(repaired)}")
                logger.info(f"   ‚úÖ JSON reparado exitosamente - Tipo: {type(analysis_data)}")
            except Exception as repair_error:
                logger.error(f"   ‚ùå No se pudo reparar JSON: {repair_error}")
                raise HTTPException(
                    status_code=500,
                    detail=f"OpenAI no devolvi√≥ JSON v√°lido. Respuesta guardada en {raw_path}"
                )
        
        # Verificar que sea un dict
        if not isinstance(analysis_data, dict):
            logger.error(f"   ‚ùå analysis_data no es un dict, es: {type(analysis_data)}")
            logger.error(f"   üìù Contenido: {str(analysis_data)[:500]}")
            raw_path = reports_dir / f"{run_id}_raw_response.txt"
            with open(raw_path, 'w', encoding='utf-8') as f:
                f.write(analysis)
            raise HTTPException(
                status_code=500,
                detail=f"OpenAI response is not a valid JSON object, got {type(analysis_data)}. Respuesta guardada en {raw_path}"
            )
        
        json_path = reports_dir / f"{run_id}_analysis_complete.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"   ‚úÖ JSON guardado: {json_path}")
        
        # PASO 9: Generar PDF
        logger.info("\nüìÑ PASO 9: Generando PDF profesional...")
        pdf_path = reports_dir / f"Reporte_Analisis_Completo_{run_id}.pdf"
        
        pdf_generator = PDFGenerator(str(pdf_path))
        final_pdf_path = pdf_generator.generate(analysis_data)
        
        logger.info(f"   ‚úÖ PDF generado: {final_pdf_path}")
        logger.info("="*80)
        logger.info("‚úÖ AN√ÅLISIS COMPLETO FINALIZADO")
        logger.info("="*80)
        
        return {
            "status": "success",
            "run_id": run_id,
            "pdf_path": str(final_pdf_path),
            "json_report": str(json_path),
            "total_ads_in_csv": len(df),
            "total_images_processed": total_imgs,
            "total_video_frames_processed": total_video_frames,
            "tokens_used": tokens_used,
            "message": "An√°lisis completo de TODOS los anuncios finalizado exitosamente"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error in analyze-local-and-pdf: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/analyze-url-with-download", status_code=200)
async def analyze_url_with_download(request: SimpleScrapeRequest):
    """
    Endpoint para analizar una URL que descarga el dataset si no existe localmente.
    
    Este endpoint:
    1. Verifica si el run_id ya existe localmente
    2. Si no existe, hace scraping y descarga el dataset
    3. Si existe, verifica que tenga los archivos necesarios
    4. Si faltan archivos, descarga el dataset desde Apify
    5. Procede con el an√°lisis local y generaci√≥n de PDF
    
    Args:
        request: SimpleScrapeRequest con url, count, timeout
        
    Returns:
        JSON con paths al PDF y reporte JSON generados
    """
    try:
        from ...routes.scraper import scrape_and_save
        import asyncio
        
        logger.info("="*80)
        logger.info(f"üöÄ AN√ÅLISIS URL CON DESCARGA AUTOM√ÅTICA - URL: {request.url}")
        logger.info("="*80)
        
        # PASO 1: Hacer scraping para obtener run_id
        logger.info("\nüì° PASO 1: Iniciando scraping...")
        scrape_result = await scrape_and_save(request)
        run_id = scrape_result['run_id']
        logger.info(f"   ‚úÖ Run ID obtenido: {run_id}")
        
        # PASO 2: Verificar si el dataset existe localmente
        logger.info("\nüìä PASO 2: Verificando dataset local...")
        base_dir = get_facebook_saved_base()
        run_dir = base_dir / run_id
        csv_path = run_dir / f"{run_id}.csv"
        jsonl_path = run_dir / f"{run_id}.jsonl"
        media_dir = run_dir / "media"
        
        dataset_exists = csv_path.exists() or jsonl_path.exists()
        media_exists = media_dir.exists() and any(media_dir.iterdir())
        
        logger.info(f"   üìÅ CSV existe: {csv_path.exists()}")
        logger.info(f"   üìÅ JSONL existe: {jsonl_path.exists()}")
        logger.info(f"   üìÅ Media existe: {media_exists}")
        
        # PASO 3: Si no existe el dataset o faltan archivos, descargarlo
        if not dataset_exists or not media_exists:
            logger.info("\nüíæ PASO 3: Descargando dataset desde Apify...")
            
            from app.processors.facebook.extract_dataset import fetch_and_store_run_dataset
            
            try:
                # Descargar dataset con media
                dataset_meta = await asyncio.to_thread(
                    fetch_and_store_run_dataset,
                    run_id,
                    out_base=None,  # usa directorio por defecto
                    download_media=True,
                    download_limit=None
                )
                
                logger.info(f"   ‚úÖ Dataset descargado: {dataset_meta.get('items_count', 0)} items")
                if dataset_meta.get('media_saved_count'):
                    logger.info(f"   ‚úÖ Media descargado: {dataset_meta.get('media_saved_count')} archivos")
            except Exception as e:
                logger.warning(f"   ‚ö†Ô∏è  Error descargando dataset: {e}")
                logger.info("   ‚ÑπÔ∏è  Continuando con datos existentes...")
        else:
            logger.info("\n‚úÖ PASO 3: Dataset ya existe localmente, omitiendo descarga")
        
        # PASO 4: Verificar que ahora s√≠ existan los archivos necesarios
        csv_path = run_dir / f"{run_id}.csv"
        if not csv_path.exists():
            raise HTTPException(404, f"CSV no encontrado despu√©s de descarga en {csv_path}")
        
        # PASO 5: Detectar y extraer frames de videos (DETECCI√ìN ROBUSTA)
        logger.info("\nüé¨ PASO 5: Detectando y extrayendo frames de videos...")
        video_frames_dir = run_dir / "video_frames"
        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm', '.m4v', '.flv', '.wmv']
        
        # Funci√≥n para detectar si un archivo es realmente un video
        def is_valid_video_file(file_path: Path) -> bool:
            """Verifica si un archivo es un video v√°lido."""
            # Verificar por extensi√≥n
            if file_path.suffix.lower() not in video_extensions:
                return False
            
            # Verificar que el archivo exista y tenga contenido
            if not file_path.exists() or file_path.stat().st_size == 0:
                return False
            
            # Intentar abrir con OpenCV para validar
            try:
                import cv2
                cap = cv2.VideoCapture(str(file_path))
                if cap.isOpened():
                    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    fps = cap.get(cv2.CAP_PROP_FPS)
                    cap.release()
                    # Un video v√°lido debe tener al menos 1 frame y FPS > 0
                    if frame_count > 0 and fps > 0:
                        return True
            except Exception:
                pass
            
            return False
        
        # Verificar si ya existen frames extra√≠dos
        has_video_frames = False
        existing_frames = []
        if video_frames_dir.exists():
            existing_frames = [
                f for f in video_frames_dir.iterdir() 
                if f.is_file() and f.suffix.lower() in ['.jpg', '.jpeg', '.png']
            ]
            if existing_frames:
                logger.info(f"   ‚úÖ {len(existing_frames)} frames de video ya existen en el directorio")
                has_video_frames = True
        
        # Si no hay frames suficientes, buscar videos y extraerlos
        if not has_video_frames or len(existing_frames) < 10:  # Extraer m√°s si hay pocos frames
            logger.info(f"   üîç Buscando archivos de video en {media_dir}...")
            
            # Listar todos los archivos en media_dir
            all_files = [f for f in media_dir.iterdir() if f.is_file()]
            logger.info(f"   üìÅ Total archivos en media/: {len(all_files)}")
            
            # Intentar detectar videos de m√∫ltiples formas
            potential_videos = []
            for file_path in all_files:
                # Verificar por extensi√≥n
                if file_path.suffix.lower() in video_extensions:
                    potential_videos.append(file_path)
                    logger.info(f"      üìπ Detectado por extensi√≥n: {file_path.name}")
            
            # Si no encontramos por extensi√≥n, buscar por tama√±o (videos suelen ser m√°s grandes)
            if not potential_videos:
                logger.info(f"   üîç No se encontraron videos por extensi√≥n, buscando por tama√±o...")
                # Archivos > 100KB que no sean im√°genes conocidas
                image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp']
                large_files = [
                    f for f in all_files 
                    if f.suffix.lower() not in image_extensions 
                    and f.stat().st_size > 100 * 1024  # > 100KB
                ]
                logger.info(f"   üìä Archivos grandes encontrados (>100KB): {len(large_files)}")
                potential_videos = large_files[:10]  # Limitar para no procesar demasiados
            
            # Validar cada video potencial
            valid_video_files = []
            for video_path in potential_videos:
                if is_valid_video_file(video_path):
                    valid_video_files.append(video_path)
                    logger.info(f"   ‚úÖ Video v√°lido confirmado: {video_path.name}")
                else:
                    logger.debug(f"   ‚ö†Ô∏è  {video_path.name} no es un video v√°lido")
            
            if valid_video_files:
                logger.info(f"   üìπ {len(valid_video_files)} videos v√°lidos encontrados, extrayendo frames...")
                video_frames_dir.mkdir(exist_ok=True, parents=True)
                
                try:
                    import cv2
                    frames_extracted = 0
                    max_frames_per_video = max(1, max_video_frames // max(1, len(valid_video_files)))
                    
                    for video_path in valid_video_files:
                        if frames_extracted >= max_video_frames:
                            break
                            
                        try:
                            cap = cv2.VideoCapture(str(video_path))
                            if not cap.isOpened():
                                logger.warning(f"      ‚ö†Ô∏è  No se pudo abrir {video_path.name}")
                                continue
                                
                            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                            fps = cap.get(cv2.CAP_PROP_FPS)
                            
                            if frame_count == 0 or fps == 0:
                                logger.warning(f"      ‚ö†Ô∏è  Video {video_path.name} inv√°lido (frames: {frame_count}, fps: {fps})")
                                cap.release()
                                continue
                            
                            # Extraer m√∫ltiples frames distribuidos a lo largo del video
                            # Para cumplir con el 40% (20 frames de ~50 totales)
                            num_frames_to_extract = min(max_frames_per_video, max_video_frames - frames_extracted)
                            
                            if num_frames_to_extract > 0:
                                # Distribuir frames equitativamente
                                frame_indices = []
                                if num_frames_to_extract == 1:
                                    frame_indices = [frame_count // 2]
                                else:
                                    step = frame_count / (num_frames_to_extract + 1)
                                    frame_indices = [int(i * step) for i in range(1, num_frames_to_extract + 1)]
                                
                                base_name = video_path.stem
                                
                                for idx, frame_num in enumerate(frame_indices):
                                    if frames_extracted >= max_video_frames:
                                        break
                                    
                                    cap.set(cv2.CAP_PROP_POS_FRAMES, min(frame_num, frame_count - 1))
                                    ret, frame = cap.read()
                                    if ret and frame is not None:
                                        frame_filename = f"{base_name}_frame{idx:03d}.jpg"
                                        frame_path = video_frames_dir / frame_filename
                                        
                                        # Redimensionar frame si es muy grande
                                        h, w = frame.shape[:2]
                                        if max(h, w) > 1920:
                                            scale = 1920 / max(h, w)
                                            new_w, new_h = int(w * scale), int(h * scale)
                                            frame = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
                                        
                                        cv2.imwrite(str(frame_path), frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
                                        frames_extracted += 1
                                        
                                logger.info(f"      ‚úÖ {video_path.name}: {num_frames_to_extract} frames extra√≠dos")
                            
                            cap.release()
                        except Exception as e:
                            logger.error(f"      ‚ùå Error procesando {video_path.name}: {e}")
                            import traceback
                            logger.debug(traceback.format_exc())
                    
                    # Verificar frames extra√≠dos
                    if video_frames_dir.exists():
                        existing_frames = [
                            f for f in video_frames_dir.iterdir() 
                            if f.is_file() and f.suffix.lower() in ['.jpg', '.jpeg', '.png']
                        ]
                        has_video_frames = len(existing_frames) > 0
                        if has_video_frames:
                            logger.info(f"   ‚úÖ Total: {len(existing_frames)} frames de video extra√≠dos exitosamente")
                        else:
                            logger.warning(f"   ‚ö†Ô∏è  No se pudieron extraer frames de video (directorio vac√≠o)")
                    else:
                        logger.warning(f"   ‚ö†Ô∏è  No se cre√≥ el directorio de frames")
                        
                except ImportError:
                    logger.error("   ‚ùå OpenCV no disponible. Instala opencv-python: pip install opencv-python")
                except Exception as e:
                    logger.error(f"   ‚ùå Error durante extracci√≥n de frames: {e}")
                    import traceback
                    logger.error(traceback.format_exc())
            else:
                logger.warning(f"   ‚ö†Ô∏è  No se encontraron videos v√°lidos en el dataset")
                logger.info(f"   üí° Los anuncios pueden ser solo im√°genes est√°ticas")
        
        # PASO 6: Preparar contenido para OpenAI con Base64
        logger.info("\nüñºÔ∏è  PASO 6: Preparando im√°genes en Base64...")
        
        from openai import AsyncOpenAI
        
        api_key = os.getenv("OPENAI_API_KEY") or os.getenv("OPEN_API_KEY")
        if not api_key:
            raise HTTPException(503, "OPENAI_API_KEY no configurada")
        
        openai_client = AsyncOpenAI(api_key=api_key)
        
        # Cargar CSV
        df = pd.read_csv(csv_path)
        logger.info(f"   üìÑ CSV cargado: {len(df)} anuncios totales")
        
        MAX_IMAGES = 50
        max_static_images = int(MAX_IMAGES * 0.6)  # 60% = 30 im√°genes
        max_video_frames = int(MAX_IMAGES * 0.4)   # 40% = 20 frames
        
        logger.info(f"   ‚öôÔ∏è  L√≠mite total: {MAX_IMAGES}")
        logger.info(f"   üìä Proporci√≥n: {max_static_images} im√°genes + {max_video_frames} frames de video")
        
        # Cargar prompt desde .env o archivo (igual que el otro endpoint)
        prompt_template = os.getenv('PROMPT')
        
        if not prompt_template:
            prompt_file_name = os.getenv('PROMPT_FILE', 'prompt.txt')
            api_service_dir = Path(__file__).parent.parent.parent.parent.parent.parent.parent
            prompt_path = api_service_dir / prompt_file_name
            
            if prompt_path.exists():
                with open(prompt_path, "r", encoding="utf-8") as f:
                    prompt_template = f.read().strip()
                logger.info(f"   ‚úÖ Prompt cargado desde {prompt_file_name}")
            else:
                try:
                    from app.api.routes.apify.facebook.analysis.prompts import DEFAULT_PROMPT
                    prompt_template = DEFAULT_PROMPT
                except ImportError:
                    prompt_template = "Analiza estos anuncios de Facebook de manera PROFUNDA y DETALLADA. TODO en ESPA√ëOL."
        else:
            logger.info(f"   ‚úÖ Prompt cargado desde variable PROMPT del .env")
        
        dataset_info = f"""
INFORMACI√ìN DEL DATASET:
- Run ID: {run_id}
- Total de anuncios: {len(df)}
- Im√°genes est√°ticas: {max_static_images}
- Frames de video: {max_video_frames}
- Total multimedia: {MAX_IMAGES}

INSTRUCCI√ìN CR√çTICA: 
- Debes retornar √öNICAMENTE un objeto JSON v√°lido y completo
- TODO en ESPA√ëOL
- An√°lisis PROFUNDO y DETALLADO
- Contrasta im√°genes est√°ticas con frames de video
- No agregues texto adicional antes o despu√©s del JSON

### FORMATO DE SALIDA REQUERIDO (JSON):
{{
  "report_meta": {{
    "generated_role": "Senior Data Scientist & Marketing Director",
    "brand_detected": "(Nombre de la marca identificada en los anuncios)",
    "ranking_metric_used": "(M√©trica principal analizada)",
    "sample_size": "{len(df)} anuncios analizados"
  }},
  "executive_summary": {{
    "performance_overview": "(Resumen estrat√©gico PROFUNDO y DETALLADO de los hallazgos principales. M√≠nimo 200 palabras explicando patrones, tendencias y conclusiones clave)",
    "common_success_patterns": "(Patrones visuales, narrativos o estrat√©gicos recurrentes encontrados)"
  }},
  "top_10_analysis": [
    {{
      "rank": 1,
      "ad_id": "(ID o identificador del anuncio)",
      "metrics": {{
        "primary_metric_value": "(Valor principal si est√° disponible)",
        "ctr": "(CTR si est√° disponible)",
        "spend": "(Gasto si est√° disponible)"
      }},
      "forensic_breakdown": {{
        "hook_strategy": "(An√°lisis DETALLADO del gancho visual en los primeros 3 segundos)",
        "audio_mood": "(Descripci√≥n profesional del audio y su impacto)",
        "narrative_structure": "(Estructura narrativa: Problema/Soluci√≥n, UGC, Testimonial, etc.)"
      }},
      "expert_scores": {{
        "visual_hook": 9,
        "storytelling": 8,
        "brand_integration": 9,
        "conversion_driver": 10
      }},
      "key_takeaway": "(Conclusi√≥n DETALLADA de una o dos frases sobre este anuncio)"
    }}
  ],
  "strategic_recommendations": [
    "(Recomendaci√≥n estrat√©gica 1 - DETALLADA y ACCIONABLE)",
    "(Recomendaci√≥n estrat√©gica 2 - DETALLADA y ACCIONABLE)",
    "(Recomendaci√≥n estrat√©gica 3 - DETALLADA y ACCIONABLE)"
  ]
}}

IMPORTANTE: 
- El campo "performance_overview" debe ser EXTENSIVO y DETALLADO (m√≠nimo 200 palabras)
- Analiza TODOS los anuncios proporcionados, no solo los top 10
- Proporciona insights profundos basados en las im√°genes y frames de video analizados
- Las recomendaciones deben ser espec√≠ficas y accionables
"""
        
        content_blocks = []
        content_blocks.append({
            "type": "text",
            "text": dataset_info + "\n\n" + prompt_template
        })
        
        total_imgs = 0
        total_video_frames = 0
        
        # PRIMERO: Procesar frames de video (40%) - PRIORITARIO si est√°n disponibles
        if has_video_frames and video_frames_dir.exists():
            logger.info(f"\n   üìπ PASO 6.1: Procesando hasta {max_video_frames} frames de video (40% del total)...")
            video_frame_files = sorted([
                f for f in video_frames_dir.iterdir() 
                if f.is_file() and f.suffix.lower() in ['.jpg', '.jpeg', '.png']
            ], key=lambda x: x.stat().st_mtime)  # Ordenar por fecha de modificaci√≥n
            
            logger.info(f"   üìä {len(video_frame_files)} frames disponibles para procesar")
            
            if not video_frame_files:
                logger.warning(f"   ‚ö†Ô∏è  No hay frames disponibles aunque has_video_frames=True")
                has_video_frames = False
            else:
                # Procesar frames hasta alcanzar el 40% del total (m√°ximo)
                frames_to_process = min(len(video_frame_files), max_video_frames)
                
                for idx, frame_file in enumerate(video_frame_files[:frames_to_process]):
                    if total_video_frames >= max_video_frames:
                        logger.info(f"   ‚ö†Ô∏è  L√≠mite de {max_video_frames} frames alcanzado")
                        break
                        
                    try:
                        with Image.open(frame_file) as img:
                            if img.mode in ('RGBA', 'P', 'LA'):
                                img = img.convert('RGB')
                            
                            # Redimensionar si es muy grande (optimizar para OpenAI)
                            if max(img.size) > 800:
                                img.thumbnail((800, 800), Image.Resampling.LANCZOS)
                            
                            buffered = BytesIO()
                            img.save(buffered, format="JPEG", quality=85, optimize=True)
                            b64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
                            
                            content_blocks.append({
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{b64}",
                                    "detail": "high"
                                }
                            })
                            total_video_frames += 1
                            
                            if total_video_frames % 5 == 0:
                                logger.info(f"   ‚úì Procesados {total_video_frames}/{max_video_frames} frames...")
                                
                    except Exception as e:
                        logger.error(f"   ‚úó Error procesando frame {frame_file.name}: {e}")
                        import traceback
                        logger.debug(traceback.format_exc())
                
                if total_video_frames == 0:
                    logger.warning(f"   ‚ö†Ô∏è  NO SE PROCESARON frames de video - revisar archivos")
                    has_video_frames = False
                else:
                    logger.info(f"   ‚úÖ Total frames de video procesados: {total_video_frames}/{max_video_frames}")
        else:
            if not video_frames_dir.exists():
                logger.info(f"   ‚ÑπÔ∏è  Directorio de frames no existe: {video_frames_dir}")
            logger.warning(f"   ‚ö†Ô∏è  NO HAY frames de video disponibles - balance ser√° 100% im√°genes est√°ticas")
            
        # Ajustar proporci√≥n de im√°genes est√°ticas si tenemos frames de video
        if total_video_frames > 0:
            # Si tenemos frames, ajustar el l√≠mite de im√°genes est√°ticas
            remaining_slots = MAX_IMAGES - total_video_frames
            max_static_images = min(max_static_images, remaining_slots)
            logger.info(f"   üìä Ajuste de proporci√≥n: {total_video_frames} frames ({int(total_video_frames/MAX_IMAGES*100)}%) + hasta {max_static_images} im√°genes ({int(max_static_images/MAX_IMAGES*100)}%)")
        
        # SEGUNDO: Procesar im√°genes est√°ticas (60% o el resto disponible)
        logger.info(f"\n   üñºÔ∏è  PASO 6.2: Procesando hasta {max_static_images} im√°genes est√°ticas...")
        
        # Filtrar im√°genes (excluir videos)
        image_extensions = ['.jpg', '.jpeg', '.png', '.webp', '.gif', '.bmp']
        image_files = [
            f for f in media_dir.iterdir() 
            if f.is_file() 
            and f.suffix.lower() in image_extensions
            and f.suffix.lower() not in ['.mp4', '.avi', '.mov', '.mkv', '.webm', '.m4v', '.flv', '.wmv']  # Excluir videos
        ]
        
        logger.info(f"   üìä {len(image_files)} im√°genes est√°ticas encontradas")
        
        if not image_files:
            logger.warning(f"   ‚ö†Ô∏è  No se encontraron im√°genes est√°ticas en {media_dir}")
        else:
            # Ordenar por tama√±o o nombre para consistencia
            image_files = sorted(image_files, key=lambda x: x.stat().st_size, reverse=True)
            
            for img_file in image_files:
                if total_imgs >= max_static_images:
                    logger.info(f"   ‚ö†Ô∏è  L√≠mite de {max_static_images} im√°genes alcanzado")
                    break
                
                try:
                    with Image.open(img_file) as img:
                        # Validar que sea realmente una imagen v√°lida
                        img.verify()
                        
                    # Reabrir porque verify() cierra la imagen
                    with Image.open(img_file) as img:
                        if img.mode in ('RGBA', 'P', 'LA'):
                            img = img.convert('RGB')
                        
                        # Redimensionar si es muy grande (optimizar para OpenAI)
                        if max(img.size) > 800:
                            img.thumbnail((800, 800), Image.Resampling.LANCZOS)
                        
                        buffered = BytesIO()
                        img.save(buffered, format="JPEG", quality=85, optimize=True)
                        b64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
                        
                        content_blocks.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{b64}",
                                "detail": "high"
                            }
                        })
                        total_imgs += 1
                        
                        if total_imgs % 10 == 0:
                            logger.info(f"   ‚úì Procesadas {total_imgs}/{max_static_images} im√°genes...")
                            
                except Exception as e:
                    logger.warning(f"   ‚ö†Ô∏è  Error procesando imagen {img_file.name}: {e}")
                    # Continuar con la siguiente imagen
        
        logger.info(f"   ‚úÖ Total im√°genes est√°ticas procesadas: {total_imgs}/{max_static_images}")
        
        # Validar balance: asegurar que hay frames si deber√≠a haberlos
        if total_video_frames == 0 and has_video_frames:
            logger.error(f"   ‚ùå ERROR: Se esperaban frames de video pero no se procesaron")
            logger.error(f"   üìÅ Verificando directorio: {video_frames_dir}")
            if video_frames_dir.exists():
                logger.error(f"   üìÇ Contenido: {list(video_frames_dir.iterdir())}")
        
        # PASO 7: Enviar a OpenAI con Base64
        logger.info("\nü§ñ PASO 7: Enviando a OpenAI...")
        logger.info(f"   üìä Total: {total_imgs} im√°genes + {total_video_frames} frames de video")
        logger.info(f"   üìä Balance: {int((total_video_frames/(total_imgs+total_video_frames)*100) if (total_imgs+total_video_frames) > 0 else 0)}% frames, {int((total_imgs/(total_imgs+total_video_frames)*100) if (total_imgs+total_video_frames) > 0 else 0)}% im√°genes")
        
        total_assets = total_imgs + total_video_frames
        if total_assets == 0:
            raise HTTPException(400, "No se proces√≥ ninguna multimedia")
        
        # Validar que tenemos contenido para enviar
        if not content_blocks:
            raise HTTPException(400, "No se prepar√≥ contenido para enviar a OpenAI")
        
        # Validar que tenemos al menos texto o im√°genes
        has_text = any(block.get("type") == "text" for block in content_blocks)
        has_images = any(block.get("type") == "image_url" for block in content_blocks)
        
        if not has_text:
            logger.warning("   ‚ö†Ô∏è  No hay contenido de texto, agregando prompt m√≠nimo...")
            content_blocks.insert(0, {
                "type": "text",
                "text": "Analiza estos anuncios publicitarios de Facebook de manera PROFUNDA y DETALLADA. TODO en ESPA√ëOL."
            })
        
        if not has_images:
            raise HTTPException(400, f"No se encontraron im√°genes para analizar (total assets: {total_assets})")
        
        logger.info(f"   üìä Payload preparado: {len([b for b in content_blocks if b.get('type') == 'text'])} bloques de texto, {len([b for b in content_blocks if b.get('type') == 'image_url'])} im√°genes")
        
        # Validar formato del payload antes de enviar
        try:
            import json as json_validate
            # Intentar serializar para validar formato
            json_validate.dumps(content_blocks)
            logger.info("   ‚úÖ Formato del payload validado correctamente")
        except Exception as e:
            logger.error(f"   ‚ùå Error validando formato del payload: {e}")
            raise HTTPException(500, f"Error en formato del payload: {e}")
        
        try:
            response = await openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": "Eres un experto analista de marketing digital y publicidad. IMPORTANTE: Toda tu respuesta debe ser en ESPA√ëOL. Debes analizar anuncios publicitarios de manera profesional y proporcionar an√°lisis profundos y detallados. Retorna √öNICAMENTE un objeto JSON v√°lido sin texto adicional antes o despu√©s del JSON."
                    },
                    {"role": "user", "content": content_blocks}
                ],
                response_format={"type": "json_object"}
                # Sin l√≠mite de max_tokens para permitir respuesta completa
            )
        except Exception as e:
            logger.error(f"   ‚ùå Error llamando a OpenAI: {type(e).__name__}: {e}")
            import traceback
            logger.error(f"   üìã Traceback: {traceback.format_exc()}")
            raise HTTPException(500, f"Error en llamada a OpenAI: {str(e)}")
        
        analysis = response.choices[0].message.content
        tokens_used = response.usage.total_tokens if hasattr(response, 'usage') and response.usage else 0
        
        logger.info(f"   üìù Respuesta recibida: {len(analysis) if analysis else 0} caracteres, {tokens_used} tokens usados")
        
        # Verificar si OpenAI rechaz√≥ la solicitud o devolvi√≥ respuesta vac√≠a
        if not analysis or len(analysis.strip()) == 0:
            logger.error(f"   ‚ùå OpenAI devolvi√≥ respuesta VAC√çA")
            raise HTTPException(
                status_code=500,
                detail="OpenAI devolvi√≥ una respuesta vac√≠a. Verifica que el contenido enviado sea v√°lido."
            )
        
        if "no puedo ayudar" in analysis.lower() or "sorry" in analysis.lower() or "cannot" in analysis.lower() or "i can't" in analysis.lower():
            logger.error(f"   ‚ùå OpenAI rechaz√≥ la solicitud: {analysis[:200]}")
            # Guardar respuesta para debugging
            raw_path = run_dir / "reports" / f"{run_id}_rejected_response.txt"
            raw_path.parent.mkdir(exist_ok=True, parents=True)
            with open(raw_path, 'w', encoding='utf-8') as f:
                f.write(analysis)
            logger.error(f"   üìÑ Respuesta rechazada guardada en: {raw_path}")
            raise HTTPException(
                status_code=500,
                detail="OpenAI rechaz√≥ la solicitud. Esto puede deberse a filtros de contenido. Respuesta guardada para revisi√≥n."
            )
        
        # Parsear JSON
        analysis_data = None
        try:
            analysis_data = json.loads(analysis)
            logger.info("   ‚úÖ JSON parseado correctamente")
        except json.JSONDecodeError as e:
            logger.warning(f"   ‚ö†Ô∏è  Error parseando JSON: {e}")
            try:
                from json_repair import loads as repair_loads
                repaired = repair_loads(analysis)
                # Asegurar que sea un dict, no un string
                if isinstance(repaired, str):
                    analysis_data = json.loads(repaired)
                elif isinstance(repaired, dict):
                    analysis_data = repaired
                else:
                    raise ValueError(f"json_repair devolvi√≥ un tipo inesperado: {type(repaired)}")
                logger.info(f"   ‚úÖ JSON reparado exitosamente")
            except Exception as repair_error:
                logger.error(f"   ‚ùå No se pudo reparar JSON: {repair_error}")
                raise HTTPException(500, f"OpenAI no devolvi√≥ JSON v√°lido: {repair_error}")
        
        # Verificar que sea un dict
        if not isinstance(analysis_data, dict):
            raise HTTPException(
                status_code=500,
                detail=f"OpenAI response is not a valid JSON object, got {type(analysis_data)}"
            )
        
        # Guardar JSON
        reports_dir = run_dir / "reports"
        reports_dir.mkdir(exist_ok=True)
        json_path = reports_dir / f"{run_id}_analysis_complete.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, indent=2, ensure_ascii=False)
        
        # Generar PDF
        logger.info("\nüìÑ Generando PDF...")
        pdf_path = reports_dir / f"Reporte_Analisis_Completo_{run_id}.pdf"
        pdf_generator = PDFGenerator(str(pdf_path))
        final_pdf_path = pdf_generator.generate(analysis_data)
        
        
        logger.info("="*80)
        logger.info("‚úÖ AN√ÅLISIS COMPLETO FINALIZADO")
        logger.info("="*80)
        
        return {
            "status": "success",
            "run_id": run_id,
            "pdf_path": str(final_pdf_path),
            "json_report": str(json_path),
            "total_ads_in_csv": len(df),
            "total_images_processed": total_imgs,
            "total_video_frames_processed": total_video_frames,
            "tokens_used": tokens_used,
            "dataset_downloaded": not dataset_exists or not media_exists,
            "message": "An√°lisis completo finalizado exitosamente"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error in analyze-url-with-download: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/pdf/{run_id}", tags=["ai-analysis"])
async def download_pdf(run_id: str):
    """
    Endpoint para descargar el PDF generado para un run_id.
    
    Busca el PDF en la ruta: {base_dir}/{run_id}/reports/Reporte_Analisis_Completo_{run_id}.pdf
    
    Args:
        run_id: ID del run
        
    Returns:
        FileResponse con el PDF para descarga
    """
    try:
        base_dir = get_facebook_saved_base()
        run_dir = base_dir / run_id
        reports_dir = run_dir / "reports"
        pdf_filename = f"Reporte_Analisis_Completo_{run_id}.pdf"
        pdf_path = reports_dir / pdf_filename
        
        if not pdf_path.exists():
            raise HTTPException(
                status_code=404,
                detail=f"PDF no encontrado para run_id: {run_id}. Aseg√∫rate de haber ejecutado el an√°lisis primero."
            )
        
        return FileResponse(
            path=str(pdf_path),
            filename=pdf_filename,
            media_type="application/pdf",
            headers={"Content-Disposition": f'attachment; filename="{pdf_filename}"'}
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error descargando PDF para run_id {run_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))
