# 02. Gesti√≥n de Datasets

## üìã Descripci√≥n General

El sistema incluye funcionalidades completas para gestionar datasets descargados de Facebook Ads Library. Permite listar, consultar, descargar, eliminar y limpiar datasets de forma eficiente.

## üéØ Prop√≥sito

- Organizar y gestionar m√∫ltiples datasets descargados
- Facilitar el acceso a datos hist√≥ricos
- Optimizar el uso de espacio en disco
- Mantener trazabilidad de an√°lisis realizados
- Reutilizar datasets para m√∫ltiples an√°lisis

## üìÅ Estructura de Datasets

### Organizaci√≥n de Archivos

```
api_service/app/processors/datasets/saved_datasets/facebook/
‚îú‚îÄ‚îÄ {run_id_1}/
‚îÇ   ‚îú‚îÄ‚îÄ {run_id_1}.csv
‚îÇ   ‚îú‚îÄ‚îÄ {run_id_1}.jsonl
‚îÇ   ‚îú‚îÄ‚îÄ media/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ imagen1.jpg
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ video1.mp4
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ video_frames/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ reports/
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ {run_id_2}/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ ...
```

### Componentes de un Dataset

1. **CSV**: Metadatos estructurados en formato tabular
2. **JSONL**: Datos en formato JSON l√≠nea por l√≠nea
3. **media/**: Archivos multimedia descargados (im√°genes y videos)
4. **video_frames/**: Frames extra√≠dos de videos (si se procesaron)
5. **reports/**: Reportes generados de an√°lisis (PDF, JSON)

## üì° Endpoints Disponibles

### GET `/api/v1/apify/facebook/runs/list`

Lista todos los datasets disponibles localmente.

#### Respuesta

```json
{
  "status": "success",
  "total_runs": 5,
  "runs": [
    {
      "run_id": "bfMXWLphPQcDmBsrz",
      "path": "D:/.../datasets/facebook/bfMXWLphPQcDmBsrz",
      "has_csv": true,
      "has_jsonl": true,
      "has_media": true,
      "media_count": 147,
      "created_at": "2025-11-24T10:30:00",
      "size_bytes": 15728640
    }
  ]
}
```

#### Uso

```bash
curl "http://localhost:8001/api/v1/apify/facebook/runs/list"
```

**Casos de uso**:
- Ver qu√© datasets est√°n disponibles
- Verificar tama√±o de almacenamiento usado
- Identificar datasets para an√°lisis
- Auditor√≠a de almacenamiento

### GET `/api/v1/apify/facebook/runs/{run_id}`

Obtiene informaci√≥n detallada de un dataset espec√≠fico.

#### Respuesta

```json
{
  "status": "success",
  "run_id": "bfMXWLphPQcDmBsrz",
  "exists": true,
  "path": "D:/.../datasets/facebook/bfMXWLphPQcDmBsrz",
  "files": {
    "csv": {
      "exists": true,
      "path": "bfMXWLphPQcDmBsrz.csv",
      "size_bytes": 245760,
      "rows": 147
    },
    "jsonl": {
      "exists": true,
      "path": "bfMXWLphPQcDmBsrz.jsonl",
      "size_bytes": 512000,
      "lines": 147
    },
    "media": {
      "exists": true,
      "path": "media/",
      "count": 147,
      "size_bytes": 15728640,
      "images": 143,
      "videos": 4
    },
    "video_frames": {
      "exists": true,
      "path": "video_frames/",
      "count": 12,
      "size_bytes": 1048576
    },
    "reports": {
      "exists": true,
      "path": "reports/",
      "files": [
        "Reporte_Analisis_Completo_bfMXWLphPQcDmBsrz.pdf",
        "bfMXWLphPQcDmBsrz_analysis_complete.json"
      ]
    }
  },
  "total_size_bytes": 17510400,
  "created_at": "2025-11-24T10:30:00",
  "last_modified": "2025-11-24T11:45:00"
}
```

#### Uso

```bash
curl "http://localhost:8001/api/v1/apify/facebook/runs/bfMXWLphPQcDmBsrz"
```

**Informaci√≥n proporcionada**:
- Estado de cada componente del dataset
- Tama√±os de archivos
- Cantidad de anuncios (filas en CSV)
- Cantidad de archivos multimedia
- Fechas de creaci√≥n y modificaci√≥n

### DELETE `/api/v1/apify/facebook/runs/{run_id}`

Elimina un dataset completo del sistema.

#### ‚ö†Ô∏è ADVERTENCIA

Esta operaci√≥n es **IRREVERSIBLE**. Eliminar√°:
- CSV y JSONL
- Directorio media/ completo
- Frames de video
- Reportes generados

#### Respuesta

```json
{
  "status": "success",
  "message": "Run bfMXWLphPQcDmBsrz eliminado exitosamente",
  "deleted_path": "D:/.../datasets/facebook/bfMXWLphPQcDmBsrz",
  "freed_space_bytes": 17510400
}
```

#### Uso

```bash
curl -X DELETE "http://localhost:8001/api/v1/apify/facebook/runs/bfMXWLphPQcDmBsrz"
```

**Mejores pr√°cticas**:
- Verifica primero con `GET /runs/{run_id}` antes de eliminar
- Considera hacer backup de datasets importantes
- Usa limpieza autom√°tica para datasets antiguos en lugar de eliminaci√≥n manual

### POST `/api/v1/apify/facebook/runs/cleanup`

Elimina autom√°ticamente datasets antiguos seg√∫n criterios configurables.

#### Par√°metros

```json
{
  "days_old": 30,
  "keep_recent": 10,
  "dry_run": false
}
```

| Campo | Tipo | Default | Descripci√≥n |
|-------|------|---------|-------------|
| `days_old` | integer | 30 | Eliminar datasets m√°s antiguos que X d√≠as |
| `keep_recent` | integer | 10 | Siempre mantener los N datasets m√°s recientes |
| `dry_run` | boolean | false | Si `true`, solo simula sin eliminar |

#### Respuesta

```json
{
  "status": "success",
  "dry_run": false,
  "criteria": {
    "days_old": 30,
    "keep_recent": 10
  },
  "runs_checked": 15,
  "runs_to_delete": 3,
  "runs_deleted": 3,
  "runs_kept": 12,
  "freed_space_bytes": 52428800,
  "deleted_runs": [
    {
      "run_id": "old_run_1",
      "days_old": 45,
      "size_bytes": 15728640
    }
  ]
}
```

#### Uso

```bash
# Primero simular (recomendado)
curl -X POST "http://localhost:8001/api/v1/apify/facebook/runs/cleanup" \
  -H "Content-Type: application/json" \
  -d '{
    "days_old": 30,
    "keep_recent": 10,
    "dry_run": true
  }'

# Luego ejecutar si est√° bien
curl -X POST "http://localhost:8001/api/v1/apify/facebook/runs/cleanup" \
  -H "Content-Type: application/json" \
  -d '{
    "days_old": 30,
    "keep_recent": 10,
    "dry_run": false
  }'
```

**Estrategias de limpieza**:
- **Conservadora**: `days_old=60, keep_recent=20`
- **Moderada**: `days_old=30, keep_recent=10` (recomendado)
- **Agresiva**: `days_old=7, keep_recent=5`

### POST `/api/v1/apify/facebook/download-dataset-from-run`

Descarga un dataset desde Apify si no existe localmente.

#### Par√°metros

```json
{
  "run_id": "bfMXWLphPQcDmBsrz",
  "download_media": true,
  "force_download": false
}
```

| Campo | Tipo | Default | Descripci√≥n |
|-------|------|---------|-------------|
| `run_id` | string | - | Run ID a descargar desde Apify |
| `download_media` | boolean | true | Si descargar archivos multimedia |
| `force_download` | boolean | false | Si `true`, re-descarga incluso si existe |

#### Respuesta

```json
{
  "status": "success",
  "run_id": "bfMXWLphPQcDmBsrz",
  "message": "Dataset descargado exitosamente",
  "downloaded": {
    "csv": true,
    "jsonl": true,
    "media": true,
    "media_count": 147
  },
  "path": "D:/.../datasets/facebook/bfMXWLphPQcDmBsrz",
  "size_bytes": 17510400
}
```

#### Uso

```bash
curl -X POST "http://localhost:8001/api/v1/apify/facebook/download-dataset-from-run" \
  -H "Content-Type: application/json" \
  -d '{
    "run_id": "bfMXWLphPQcDmBsrz",
    "download_media": true
  }'
```

**Cu√°ndo usar**:
- Recuperar dataset eliminado accidentalmente
- Descargar dataset en otra m√°quina
- Actualizar dataset con media faltante
- Migrar datasets entre servidores

## üîÑ Flujos de Trabajo

### Flujo 1: Auditor√≠a de Almacenamiento

```python
import requests

# 1. Listar todos los datasets
response = requests.get("http://localhost:8001/api/v1/apify/facebook/runs/list")
data = response.json()

total_size = sum(run["size_bytes"] for run in data["runs"])
print(f"Total datasets: {data['total_runs']}")
print(f"Espacio total usado: {total_size / (1024**3):.2f} GB")

# 2. Identificar datasets grandes
large_runs = [r for r in data["runs"] if r["size_bytes"] > 100 * 1024 * 1024]
print(f"Datasets >100MB: {len(large_runs)}")
```

### Flujo 2: Limpieza Autom√°tica Programada

```python
import requests
import schedule
import time

def cleanup_old_datasets():
    """Ejecuta limpieza autom√°tica cada semana"""
    response = requests.post(
        "http://localhost:8001/api/v1/apify/facebook/runs/cleanup",
        json={
            "days_old": 30,
            "keep_recent": 10,
            "dry_run": False
        }
    )
    result = response.json()
    print(f"Limpieza completada: {result['freed_space_bytes'] / (1024**2):.2f} MB liberados")

# Programar ejecuci√≥n semanal
schedule.every().week.do(cleanup_old_datasets)

while True:
    schedule.run_pending()
    time.sleep(3600)  # Verificar cada hora
```

### Flujo 3: Verificaci√≥n de Integridad

```python
import requests

def verify_dataset_integrity(run_id):
    """Verifica que un dataset est√© completo"""
    response = requests.get(
        f"http://localhost:8001/api/v1/apify/facebook/runs/{run_id}"
    )
    
    if response.status_code == 404:
        return False, "Dataset no encontrado"
    
    data = response.json()
    files = data["files"]
    
    checks = {
        "CSV": files["csv"]["exists"],
        "JSONL": files["jsonl"]["exists"],
        "Media": files["media"]["exists"],
    }
    
    all_ok = all(checks.values())
    return all_ok, checks

# Verificar dataset espec√≠fico
ok, details = verify_dataset_integrity("bfMXWLphPQcDmBsrz")
print(f"Integridad: {'OK' if ok else 'FALLO'}")
print(f"Detalles: {details}")
```

### Flujo 4: Migraci√≥n de Datasets

```python
import requests

def download_dataset_for_migration(run_id, download_media=True):
    """Descarga dataset desde Apify para migraci√≥n"""
    response = requests.post(
        "http://localhost:8001/api/v1/apify/facebook/download-dataset-from-run",
        json={
            "run_id": run_id,
            "download_media": download_media,
            "force_download": False
        }
    )
    
    if response.status_code == 200:
        data = response.json()
        print(f"Dataset descargado: {data['size_bytes'] / (1024**2):.2f} MB")
        return True
    else:
        print(f"Error: {response.json()['detail']}")
        return False

# Migrar lista de datasets
run_ids_to_migrate = ["run1", "run2", "run3"]
for run_id in run_ids_to_migrate:
    download_dataset_for_migration(run_id)
```

## üìä Gesti√≥n de Espacio en Disco

### Estimaci√≥n de Tama√±os

| Componente | Tama√±o T√≠pico | Por Anuncio |
|------------|---------------|-------------|
| CSV | 1-5 KB | ~3 KB |
| JSONL | 3-10 KB | ~5 KB |
| Imagen | 50-500 KB | ~150 KB |
| Video | 1-10 MB | ~3 MB |
| Frame de video | 50-200 KB | ~100 KB |

**Ejemplo**: Dataset con 100 anuncios (90 im√°genes, 10 videos):
- CSV: ~300 KB
- JSONL: ~500 KB
- Im√°genes: ~13.5 MB
- Videos: ~30 MB
- Frames (30 frames): ~3 MB
- **Total**: ~47 MB

### Estrategias de Optimizaci√≥n

1. **Descarga selectiva de media**: Solo descargar media cuando se necesite para an√°lisis
2. **Compresi√≥n de videos**: Comprimir videos grandes antes de almacenar
3. **Eliminaci√≥n de duplicados**: Identificar y eliminar archivos duplicados
4. **Limpieza autom√°tica**: Programar limpieza regular de datasets antiguos
5. **Almacenamiento externo**: Mover datasets antiguos a almacenamiento externo

## ‚öôÔ∏è Configuraci√≥n

### Variables de Entorno

```env
# Directorio base para datasets
DATA_DIR=data

# Directorio espec√≠fico para datasets de Facebook
DATASETS_DIR=data/datasets/facebook
```

### L√≠mites Recomendados

- **Espacio m√≠nimo**: 10 GB para desarrollo
- **Espacio recomendado**: 50+ GB para producci√≥n
- **Retenci√≥n de datos**: 30-60 d√≠as (ajustable)
- **Datasets a mantener**: 10-20 m√°s recientes

## üîç Troubleshooting

### Problema: Dataset no encontrado

**S√≠ntoma**: `GET /runs/{run_id}` retorna 404

**Soluciones**:
1. Verificar que el Run ID sea correcto
2. Listar todos los runs con `GET /runs/list`
3. Descargar desde Apify si existe all√≠
4. Verificar permisos del directorio

### Problema: No se puede eliminar dataset

**S√≠ntoma**: `DELETE /runs/{run_id}` falla

**Soluciones**:
1. Verificar permisos de escritura
2. Cerrar procesos que usen los archivos
3. Verificar que no est√© bloqueado por otro proceso
4. Intentar eliminar manualmente el directorio

### Problema: Descarga falla o es lenta

**S√≠ntoma**: `POST /download-dataset-from-run` tarda mucho o falla

**Soluciones**:
1. Verificar conexi√≥n a internet
2. Verificar token de Apify
3. Reducir `download_media` si solo necesitas metadatos
4. Descargar en horarios de menor tr√°fico
5. Verificar espacio disponible en disco

## üìà M√©tricas y Monitoreo

### M√©tricas Clave

- **Total de datasets**: Cantidad de runs almacenados
- **Espacio usado**: Tama√±o total en disco
- **Espacio disponible**: Espacio libre restante
- **Tasa de crecimiento**: MB/d√≠a de nuevos datos
- **Tasa de limpieza**: MB liberados por limpieza

### Dashboard Recomendado

```python
def get_storage_metrics():
    """Obtiene m√©tricas de almacenamiento"""
    response = requests.get("http://localhost:8001/api/v1/apify/facebook/runs/list")
    data = response.json()
    
    total_size = sum(r["size_bytes"] for r in data["runs"])
    avg_size = total_size / data["total_runs"] if data["total_runs"] > 0 else 0
    
    return {
        "total_runs": data["total_runs"],
        "total_size_gb": total_size / (1024**3),
        "avg_size_mb": avg_size / (1024**2),
        "oldest_run_days": calculate_oldest_age(data["runs"]),
        "newest_run_days": calculate_newest_age(data["runs"])
    }
```

---

**√öltima actualizaci√≥n**: Noviembre 2025

